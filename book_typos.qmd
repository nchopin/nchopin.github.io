---
title: "Typos and errors"
permalink: /book_typos
author_profile: true
---

A lot of thanks to anyone who found the errors below (their names appear in
parentheses).  Feel free to contact me if you find others. 


# Major mistakes

* 100, Exercise 8.7: the fact that the former estimator dominates the latter
  (in terms of asymptotic variance) is equivalent to the stated equality
  provided $\mathbb{Q}(\varphi)>0$ (this condition is omitted in the book). Moreover, when $w$
  is an indicator function, one has equality (both estimators have the same
  variance asymptotically). (Otmane Sakhi)

* 117, Algorithm 9.6: the last two instructions should be outside the while
  loop, not inside; i.e. while $v^m < s$, increment $m$. And, only when the
  while loop has ended, we assign $A^n$ and increment $s$.
  (Matt Wand)

* 171, Lemma 1.2: assumption that $G_t$ is upper bounded is not required.
  (Adrien Corenflos)

* 182, Lemma 11.10: this lemma is correct only if function $\varphi$ takes both
  positive and negative values. In the following calculations, this lemma is
  applied to centred functions ($\varphi$ minus its expectations). (Adam
  Johansen)

* 313, Prop. 16.6 and Algorithm 16.8: the expression for the weights (which
  define the distribution of $B_t$) is correct for the bootstrap filter, but
  not in general, as a factor $G_{t+1}(X_t^n, X_{t+1}^{B_{t+1}})$ is missing.
  (In the bootstrap filter, this factor is constant, since $G_{t+1}$ does not
  depend on the first argument in this case.) Alternatively, you can also
  replace the transition density $m_{t+1}$ by the one of the model, $p_{t+1}$,
  to obtain a correct expression. (Adrien Corenflos) Also, in light of this,
  the sentence below Prof. 16.6 is a bit daft, and should be ignored. 

* 352, two last paragraphs of Python corner: it's not true that we obtain a
  $\times k$ speed-up (where $k=$ nr of CPU core), see this blog
  [post](https://statisfaction-blog.github.io/posts/25-04-2024-numpy-broke-my-heart/numpy-broke-my-heart.html)
  for more explanation.

# Typos

* 15, Eq. (2.3): in the first matrix (before $X_{t-1}$), $0_2$ means the
  $2\times 2$ null matrix; the second term should be a vector, not a matrix, 
  i.e. $(0_2, U_t^T)^T$ (Andreas Makris)

* 41, second equation: missing $dx_{t-1}$ in the integral (Chihiro Kuraya)

* 44, first equation: $f_t$ should be $f_s$ (Chihiro Kuraya)

* 56, first equation: $M_{0:t-1}(dx_{t-1})$ should be $M_{t-1}(dx_{0:t-1}$)
  (Feras Saad)

* 59, first equation: $H_0(x_0)$ should be $H_{0:T}(x_0)$
  (Feras Saad)

* 63, (5.17), top line: the first probability distribution should be with respect to $X_t$,
  not $X_{t-1};$ i.e. $P_t(X_t \in dx_t | Y_{0:t} = y_{0:t})$ (Giovanni Diana)

* 68, likelihood of future observations in grey box: $p(y_{t+2:T}|l)$ should be
  $p_T(y_{t+2:T}|x_{t+1}=l)$ (in order to be consistent with notation for LHS)
  (Yawei Ge).

* 73, summary: mathematically equivalently -> mathematically equivalent
  (Feras Saad)

* 76, result 2 (near bottom of the page)  $y_{1:t}$ should be $y_{0:t}$ in the
  first factor of the RHS. 

* 90, MSE of normalised IS (first displayed eq.): term $\mathbb{Q}(\varphi)^2$
  should be multiplied by $\mathbb{M}(w)^2$ (Jacob Hoover).

* 92, equation below (8.5): missing sup with respect to $\varphi$ (Adrien Corenflos)

* 92, Theorem 8.5: [w] missing just before big closing parenthesis (Chihiro Kuraya)

* 116, second equation in Lemma 9.2: $V_n$ should be $V^n$ (Adrien Corenflos)

* 117, equation on last line: in middle expression, n and n - 1 should be superscripts;
  the intersection inside $\lambda(\cdot)$ should be $[C^{n-1}, C^n] \cap [\frac{m-1}{N}, \frac{m}{N}]$.
  (Chihiro Kuraya)

* 118: same issue in first multi-line equation: replace $n$ by $m$ in the interval
  $[n-1/N, n/N]$, and below the sum (second line).  (Chihiro Kuraya)

* 119^4 (display in proof of Prop 9.4): $W^n$ should be $W$. (Chihiro Kuraya)

* 119_5: estimate(d) -> estimates (Adrien Corenflos)

* 122, Ex 9.10: the first constraint is $E(W)=x$ (missing "=x"). (Omiros)

* 126: Guldas et al (2017), "volume 28" -> "volume 48, Issue 28". (Feras Saad)

* 130, Algorithm 10.1: resampling step should be based on weights 
$W_{t-1}^{1:N}$, not $W_t^{1:N}$ (Chihiro Kuraya)

* 131^4: done in the first too (two) lines... (Yawei Ge).

* 131, grey box: space missing after "approximates". (Omiros)

* 139, first box, 3rd bullet: "P_t >> M_t", should be the reverse: "P_t << M_t";
  also, $P_t(X_t \in dx_{0:t} | \ldots )$ should be $P_t(X_{0:t} \in dx_{0:t} | \ldots )$ (Feras Saad)

* 139: the following Radon-Nykodym derivative(s) exist (Adrien Corenflos)

* 144, last line of Example 10.5: the second term should be $\sigma^2[y_t^2
  e^{-\mu^\star(x_{t-1})} - 1] /2$ (Gonzalo Mena)

* 152, (10.4): missing tilde on the $X_{t-1}$ in the second term.

* 157, first displayed equation: missing $\exp$, i.e. Poisson parameter should
  be $\exp(a_k + b_k'x_t)$ (Kyurae Kim).

* 158: The corresponding Gaussian approximation has mean $x^\star$, and
  (inverse) variance $-H^\star$ (Kyurae Kim).

* 176: Proposition 11.2 should be Proposition 11.5. (Adam Johansen). 

* 180, snd line of Lemma 11.7: $\phi$ should be $\varphi$ (Chihiro Kuraya)

* 190: in both lines below the display, h should be k in $z_{t-1}$ (Suzie Brown)

* 195, Algorithm 12.1: functions $\Phi_0^n$ and $\Phi_t^n$ should read
  $\Phi_0^N$ and $\Phi_t^N$; i.e. we compute recursively $\Phi_t^N(X_t^n)$.
  (Mathieu Gerber)

* 239: in the 9th line of Alg 13.3, $H_{t-1}^{1:N}$ should be $H_t^{1:N}$ (Chihiro
  Kuraya)

* 255, first equation: $dx$ in second part is unnecessary (Rui Zhang)

* 258: $\theta^{n-1}$ should be $\theta_{n-1}$ in function $\theta$ -> $Q(\theta, \theta^{n-1})$ (Feras Saad)

* 264, second displayed equation: last product should be from $t=0$ to $T$ (not $t$)

* 267, (14.9): replace $\theta$ by $\theta_{n-1}$ in the gradient

* 282, first line: give(n) proposal (Adrien Corenflos)

* 283, last paragraph: $O(d^2)$ should be $O(d_{\theta}^2)$ (Feras Saad)

* 285, 9th line from the bottom: inequality should be $\exp(-x) \geq 1 - x$ (Javier Burroni)

* 285, 4th line before Sec 15.5: full conditional should be
  $q_k(\theta(k)|\theta(-k))$ rather than $q(\theta(k)|\theta(-k))$ (Chihiro Kuraya)

* 287, caption of Fig. 15.2: (t)he first $10^5$ simulations

* 290: simply adds an extra step that regenerate(s) the data. (Feras Saad)

* 295, Example 6.1: better behaved tha(n) (Feras Saad)

* 300, Prop 16.1: missing tilde on the $M$ of the proposed kernel (Feras Saad)

* 301^1: $(z/c)$ instead of $(Z/c)$ in the expression of $L(\theta, z)$ (Chihiro
  Kuraya)

* 308-309: capital letters $X$ and $A$ should be respectively $x$ and $a$ in
  last equation on page 308, and in the expression of $W_t^n$ in the first line
  of p. 309. Moreover, dot should be a comma at the end of the equation at the 
  bottom of p. 308.  (Feras Saad)

* 311, Alg 16.5: in the resampling step, $A_t^{2:N}$ should be sampled from
  $W_{t-1}^{1:N}$, not $W_{t}^{1:N}$. (Matt Heiner)

* 332, second paragraph of 17.2.1: covariance matrix should be set to
  $\lambda^2\hat{\Sigma}_{t-1}$; note the missing square (Mathieu Gerber) In
  fact, $\lambda$ should be replaced by $\delta$ on that page, since that quantity
  was denoted by $\delta$ in Chapter 15, and since letter $\lambda$ means something
  else in the rest of the chapter (the tempering coefficient).

* 337, Algorithm 17.3, second line of the else block: replace $\Theta_t^n$ by
  $\Theta_{t-1}^{A_t^n}$ (Adrien Corenflos)
  
* 341, Algorithm 17.5: third instruction (sampling of $\widetilde{\Theta}$)
  should be put *before* the if statement (where $r$ function is evaluated).
  (Javier Burroni)

* 342, (17.5): $p_t^\theta$ should be $p_T^\theta$
